# Hexadecimal Number System in JavaScript / Node.js

## üìå Overview
- **Base:** 16
- **Allowed Digits:** `0‚Äì9` and `A‚ÄìF` (or lowercase `a‚Äìf`)
- **A‚ÄìF Mapping:**  
  - A = 10  
  - B = 11  
  - C = 12  
  - D = 13  
  - E = 14  
  - F = 15

---

## üîπ Example Conversions

### Hexadecimal ‚Üí Decimal
Each digit is multiplied by 16 raised to the power of its position (right to left).

Example: `0x2F`  
| Digit | Position | Power of 16 | Calculation       |
|-------|----------|-------------|-------------------|
| F(15) | 0        | 16‚Å∞ = 1     | 15 √ó 1 = **15**   |
| 2     | 1        | 16¬π = 16    | 2 √ó 16 = **32**   |

**Total:** `32 + 15 = 47 (decimal)`

---

## üîπ JavaScript Representation
- **Hexadecimal Literal** ‚Üí Prefix with `0x` or `0X`
```js
let hexNum = 0x2F;
console.log(hexNum); // 47 (decimal)
```

- **Decimal ‚Üí Hexadecimal**
```js
console.log((47).toString(16)); // "2f"
```

- **Hexadecimal ‚Üí Decimal**
```js
console.log(parseInt("2F", 16)); // 47
```

---

## üìä Quick Comparison Table

| Number System | Base | Digits Allowed        | Example (Decimal Value) |
|---------------|------|-----------------------|-------------------------|
| Decimal       | 10   | 0‚Äì9                   | `10` = 10               |
| Octal         | 8    | 0‚Äì7                   | `10` = 8                |
| Hexadecimal   | 16   | 0‚Äì9, A‚ÄìF / a‚Äìf         | `10` = 16               |

---

## üí° Real-world Usage
- **Web Colors** (e.g., `#FF5733`)
- **Memory Addresses** in programming
- **Low-level Data Representation** (e.g., binary ‚Üî hex for compactness)

---


# Hexadecimal (0x) ‚Äî Step-by-step explanation for beginners

## Example code
```js
// 1. 0x in JS represents a hexadecimal number.
const digit1 = 0x843;
console.log(digit1); // 2115
```

---

## 1) ‡§Ø‡•á `0x843` ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?
- `0x` ‚Äî JavaScript ‡§Æ‡•á‡§Ç hexadecimal literal ‡§ï‡•á ‡§≤‡§ø‡§è prefix ‡§π‡•à‡•§ ‡§Æ‡§§‡§≤‡§¨ ‡§Ø‡§π number **base 16** ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§  
- `843` ‚Äî ‡§Ø‡§π hexadecimal digits ‡§π‡•à‡§Ç (‡§Ø‡§π‡§æ‡§Ç ‡§∏‡§¨ digits 0‚Äì9 ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç)‡•§ Hex ‡§Æ‡•á‡§Ç digits `0‚Äì9` ‡§î‡§∞ `A‚ÄìF` (‡§Ø‡§æ `a‚Äìf`) ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç‡•§

---

## 2) Hexadecimal ‚Üí Decimal ‡§ï‡•à‡§∏‡•á convert ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç (‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ step-by-step)

Hexadecimal ‡§Æ‡•á‡§Ç ‡§π‡§∞ digit ‡§ï‡•Ä ‡§ï‡•Å‡§≤ value = **digit √ó 16^(position)**  
Position (‡§á‡§Ç‡§°‡•á‡§ï‡•ç‡§∏) right ‡§∏‡•á 0, 1, 2,... ‡§¨‡§¢‡§º‡§§‡§æ ‡§π‡•à‡•§

‡§π‡§Æ‡§æ‡§∞‡•á number `0x843` ‡§ï‡•á digits ‡§î‡§∞ positions:
- ‡§∏‡§¨‡§∏‡•á ‡§¶‡§æ‡§π‡§ø‡§®‡•á digit = `3` ‚Üí position = 0  
- ‡§¨‡•Ä‡§ö ‡§µ‡§æ‡§≤‡§æ digit = `4` ‚Üí position = 1  
- ‡§∏‡§¨‡§∏‡•á ‡§¨‡§æ‡§è‡§Ç digit = `8` ‚Üí position = 2  

**Power of 16 (position ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞):**
- 16^0 = 1
- 16^1 = 16
- 16^2 = 256

**‡§π‡§∞ digit ‡§ï‡§æ ‡§ó‡§£‡§ø‡§§ (digit-by-digit):**
1. Rightmost: `3 √ó 16^0 = 3 √ó 1 = 3`
2. Middle:   `4 √ó 16^1 = 4 √ó 16 = 64`
3. Leftmost: `8 √ó 16^2 = 8 √ó 256 = 2048`

> ‡§Ö‡§ó‡§∞ 256√ó8 ‡§ï‡•à‡§∏‡•á ‡§Ü‡§Ø‡§æ ‡§Ø‡•á ‡§¶‡•á‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡•ã ‡§§‡•ã:
> 256 √ó 8 = (200√ó8) + (50√ó8) + (6√ó8) = 1600 + 400 + 48 = 2048

**‡§Ö‡§¨ ‡§ú‡•ã‡§°‡§º‡•á‡§Ç (step-wise addition):**
- ‡§™‡§π‡§≤‡•á ‡§¶‡•ã ‡§ï‡•ã ‡§ú‡•ã‡§°‡§º‡•ã: `3 + 64 = 67`
- ‡§´‡§ø‡§∞ ‡§§‡•Ä‡§∏‡§∞‡•á ‡§ï‡•ã ‡§ú‡•ã‡§°‡§º‡•ã: `67 + 2048 = 2115`

‡§Ø‡§æ alignment ‡§∏‡•á ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Å:
```
   2048
 +   67
 ------
   2115
```

‡§á‡§∏‡§≤‡§ø‡§è `0x843` ‡§ï‡§æ decimal ‡§Æ‡§æ‡§® **2115** ‡§π‡•à ‚Äî ‡§î‡§∞ ‡§Ø‡§π‡•Ä `console.log` ‡§Æ‡•á‡§Ç ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ‡•§

---

## 3) JavaScript ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡•ã‡§Ç decimal ‡§¶‡§ø‡§ñ‡§§‡§æ ‡§π‡•à?
- JavaScript ‡§ï‡•á number literals internal ‡§∞‡•Ç‡§™ ‡§∏‡•á numeric value ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç (decimal ‡§Æ‡•á‡§Ç ‡§¶‡§ø‡§ñ‡§æ‡§§‡•á ‡§π‡•à‡§Ç)‡•§ ‡§ú‡§¨ ‡§Ü‡§™ `console.log(0x843)` ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§§‡•ã JS ‡§â‡§∏ internal numeric (decimal) value ‡§ï‡•ã print ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‚Äî ‡§á‡§∏‡§≤‡§ø‡§è output `2115` ‡§Ü‡§§‡§æ ‡§π‡•à‡•§

---

## 4) ‡§ï‡•à‡§∏‡•á ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‚Äî ‡§õ‡•ã‡§ü‡•á code examples
```js
// Hex literal -> decimal (literal)
console.log(0x843);         // 2115

// Hex string -> decimal (parseInt ‡§ï‡•á ‡§∏‡§æ‡§•)
console.log(parseInt("843", 16)); // 2115

// Decimal -> Hex string (.toString(16))
console.log((2115).toString(16)); // "843"
```

> ‡§®‡•ã‡§ü: `.toString(16)` lowercase hex ‡§¶‡•á‡§§‡§æ ‡§π‡•à ("843") ‚Äî uppercase ‡§ö‡§æ‡§π‡§ø‡§è ‡§§‡•ã `.toString(16).toUpperCase()` ‡§ï‡§∞ ‡§≤‡•á‡§Ç‡•§

---

## 5) Quick reference / Extra notes
- Hex base = **16**. Digits: `0‚Äì9`, `A(10)`, `B(11)`, `C(12)`, `D(13)`, `E(14)`, `F(15)`.
- Hex literal JS ‡§Æ‡•á‡§Ç: `0x...` ‡§Ø‡§æ `0X...` (case-insensitive)
- Hex ‡§Æ‡•á‡§Ç letters ‡§≠‡•Ä ‡§Ü ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡•à‡§∏‡•á `0xA3F` (`A = 10`, `F = 15`).

---

## 6) Practice (‡§õ‡•ã‡§ü‡§æ exercise)
- Convert `0x1A3` to decimal step-by-step (try ‡§¶‡•á‡§ñ ‡§ï‡•á ‡§¨‡§§‡§æ‡§ì, ‡§Æ‡•à‡§Ç check ‡§ï‡§∞ ‡§¶‡•Ç‡§Å‡§ó‡§æ)‡•§

---

**Short summary:** `0x843 = 8√ó256 + 4√ó16 + 3√ó1 = 2048 + 64 + 3 = 2115` ‚Äî ‡§á‡§∏‡§≤‡§ø‡§è `console.log(0x843)` ‡§ï‡§æ output **2115** ‡§π‡•ã‡§§‡§æ ‡§π‡•à.

